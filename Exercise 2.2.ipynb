{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d403d387-8125-48bc-9629-5ba831d48128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9eaa9bb-7ed5-45c5-acff-ccf9e39654db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with all files in the folder using list comprehension\n",
    "folderpath = r\"/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018\"\n",
    "filepaths = [os.path.join(folderpath, name) for name in os.listdir(folderpath)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c35dba56-e0f7-4971-8a5c-73514364d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pd.read_csv(f) for f in filepaths), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caae17d3-c22f-4bcc-85a0-4ad13cd1c21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x7fce695f6a50>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.read_csv(f) for f in filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4cf2589-12b0-408a-a807-6822bf5e42d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      trip_id           start_time             end_time  bikeid tripduration  \\\n",
      "0  17536702.0  2018-01-01 00:12:00  2018-01-01 00:17:23  3304.0        323.0   \n",
      "1  17536703.0  2018-01-01 00:41:35  2018-01-01 00:47:52  5367.0        377.0   \n",
      "2  17536704.0  2018-01-01 00:44:46  2018-01-01 01:33:10  4599.0      2,904.0   \n",
      "3  17536705.0  2018-01-01 00:53:10  2018-01-01 01:05:37  2302.0        747.0   \n",
      "4  17536706.0  2018-01-01 00:53:37  2018-01-01 00:56:40  3696.0        183.0   \n",
      "\n",
      "   from_station_id            from_station_name  to_station_id  \\\n",
      "0             69.0       Damen Ave & Pierce Ave          159.0   \n",
      "1            253.0  Winthrop Ave & Lawrence Ave          325.0   \n",
      "2             98.0   LaSalle St & Washington St          509.0   \n",
      "3            125.0         Rush St & Hubbard St          364.0   \n",
      "4            129.0    Blue Island Ave & 18th St          205.0   \n",
      "\n",
      "                  to_station_name    usertype gender  birthyear date  avgTemp  \n",
      "0       Claremont Ave & Hirsch St  Subscriber   Male     1988.0  NaN      NaN  \n",
      "1  Clark St & Winnemac Ave (Temp)  Subscriber   Male     1984.0  NaN      NaN  \n",
      "2             Troy St & North Ave  Subscriber   Male     1989.0  NaN      NaN  \n",
      "3            Larrabee St & Oak St  Subscriber   Male     1983.0  NaN      NaN  \n",
      "4            Paulina St & 18th St  Subscriber   Male     1989.0  NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file, read it, and append to the list\n",
    "for file_path in filepaths:\n",
    "    try:\n",
    "        # Read the CSV file with specified encoding and low_memory=False\n",
    "        df = pd.read_csv(file_path, encoding='ISO-8859-1', low_memory=False)  # Adjust encoding as necessary\n",
    "        dfs.append(df)  # Append the DataFrame to the list\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into one using pd.concat\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Check the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a CSV file in the same folder as the data\n",
    "combined_df.to_csv(r'/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018/combined_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d8854ea-13d0-4d3f-ad0d-8aae3d2179f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(r'/Users/renubalaji/Documents/GitHubProjects/Bike_rental/Avg_Temps.csv')\n",
    "combined_data = pd.read_csv(r'/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018/combined_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2808e6f-24a1-40c1-b371-b902c6c3f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(combined_data, weather_data, on='date', how='left')\n",
    "merged_data.to_csv(r'/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018/merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "038caf61-4d18-4677-82cc-540cc4601b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge complete and saved to 'merged_citibike_weather.csv'\n"
     ]
    }
   ],
   "source": [
    "# 3. Ensure both DataFrames have a 'date' column. Extract date from datetime in CitiBike data if necessary.\n",
    "# Assuming there is a datetime column in citibike_df named 'start_time' (adjust to your actual column name)\n",
    "combined_data['date'] = pd.to_datetime(combined_data['start_time']).dt.date\n",
    "\n",
    "# Similarly, ensure the 'date' column in weather data is in the correct format (assuming it's already a date)\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date']).dt.date  # Adjust if 'date' column exists\n",
    "\n",
    "# 4. Merge the two DataFrames on the 'date' column\n",
    "merged_df = pd.merge(combined_data, weather_data, on='date', how='left')  # Use 'left' join to keep all CitiBike data\n",
    "\n",
    "# 5. Save the merged data to a new CSV file\n",
    "merged_df.to_csv('/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018/merged_data_new.csv', index=False)\n",
    "\n",
    "print(\"Merge complete and saved to 'merged_citibike_weather.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc99222-6d21-4a9e-a029-fcfbc169984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data_new = pd.read_csv(r'/Users/renubalaji/Documents/GitHubProjects/Bike_rental_2018/merged_data_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f3504e09-d721-49a2-8be9-8f0b36f892b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_temp_df = merged_data_new[['date', 'avgTemp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd5f845d-d85b-4aac-96bb-fb2f061ab9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01', '2018-01-01']\n"
     ]
    }
   ],
   "source": [
    "# Get the 'date' field from all average temperature readings\n",
    "data_temp = avg_temp_df['date'].tolist()  # Extract the 'date' column and convert it to a list\n",
    "\n",
    "# Optionally, print the first few dates to verify\n",
    "print(data_temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea069d4b-feef-4dda-8ad5-853f3e5ac65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results in a dataframe\n",
    "\n",
    "data_temp = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "450bab43-df3a-48a9-beb4-106634753072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the average temperature readings\n",
    "temperature_data = data_temp['avgTemp'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84633d3f-81ce-4854-94be-7ac82af52fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results in a dataframe\n",
    "\n",
    "df_temps = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5d4812d-a93e-4a33-85aa-22da69bf26b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  avgTemp\n",
      "0  2018-01-01    -18.9\n",
      "1  2018-01-01    -18.9\n",
      "2  2018-01-01    -18.9\n",
      "3  2018-01-01    -18.9\n",
      "4  2018-01-01    -18.9\n"
     ]
    }
   ],
   "source": [
    "# Correct: Extract the 'avgTemp' column from avg_temp_df, not data_temp\n",
    "temperature_data = avg_temp_df['avgTemp'].tolist()\n",
    "\n",
    "# Put the results in a new DataFrame (if needed)\n",
    "df_temps = pd.DataFrame({'date': avg_temp_df['date'], 'avgTemp': temperature_data})\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_temps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0cf6d2d-be3d-4e73-8274-776ed691c413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avgTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449375</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449376</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449377</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449378</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449379</th>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  avgTemp\n",
       "449375  2018-12-04     -0.8\n",
       "449376  2018-12-04     -0.8\n",
       "449377  2018-12-04     -0.8\n",
       "449378  2018-12-04     -0.8\n",
       "449379  2018-12-04     -0.8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec6a2ea2-064a-414c-8118-fa290b5ce36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avgTemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>-18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avgTemp\n",
       "0  2018-01-01    -18.9\n",
       "1  2018-01-01    -18.9\n",
       "2  2018-01-01    -18.9\n",
       "3  2018-01-01    -18.9\n",
       "4  2018-01-01    -18.9"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ffb0f39-3769-45e1-8768-7302e7241239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'avgTemp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names in the DataFrame\n",
    "print(df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "20th_century",
   "language": "python",
   "name": "20th_century"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
